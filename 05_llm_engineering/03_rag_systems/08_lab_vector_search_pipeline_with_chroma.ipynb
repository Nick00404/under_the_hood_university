{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d294f8a",
   "metadata": {},
   "source": [
    "ðŸ“¦ðŸ” Professor, welcome to the **RAG Engine Room** â€” where we go from raw chunks to **fully searchable vector databases**.  \n",
    "You're now building the *retrieval* backbone of assistants like Perplexity, Bing Chat, or GPT-4 with tools.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ§ª `08_lab_vector_search_pipeline_with_chroma.ipynb`  \n",
    "### ðŸ“ `05_llm_engineering/03_rag_systems`  \n",
    "> Build an **end-to-end RAG retrieval pipeline** using **ChromaDB or FAISS**  \n",
    "â†’ Embed your documents  \n",
    "â†’ Store them in a vector DB  \n",
    "â†’ Accept queries, return top-matching chunks.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Goals\n",
    "\n",
    "- Build your own **vector database**  \n",
    "- Store & index LLM embeddings from real text  \n",
    "- Process a query, **retrieve relevant chunks** via cosine similarity  \n",
    "- Prepare for integration with **LLMs like GPT for RAG-style QA**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’» Runtime Specs\n",
    "\n",
    "| Tool          | Spec                   |\n",
    "|---------------|------------------------|\n",
    "| Vector DB     | Chroma (or FAISS) âœ…  \n",
    "| Embeddings    | `sentence-transformers` âœ…  \n",
    "| Retrieval     | Cosine search âœ…  \n",
    "| Platform      | Colab-compatible âœ…  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª Section 1: Install Dependencies\n",
    "\n",
    "```bash\n",
    "!pip install chromadb sentence-transformers langchain\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Section 2: Load and Chunk Docs (reuse from previous lab)\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "docs = TextLoader(\"sample_wikipedia.txt\").load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "texts = [c.page_content for c in chunks]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Section 3: Embed Chunks\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedder.encode(texts)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ Section 4: Store in ChromaDB\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "chroma_client = chromadb.Client(Settings(allow_reset=True))\n",
    "collection = chromadb.get_or_create_collection(\"my_docs\")\n",
    "\n",
    "for i, (text, vec) in enumerate(zip(texts, embeddings)):\n",
    "    collection.add(\n",
    "        ids=[f\"doc_{i}\"],\n",
    "        documents=[text],\n",
    "        embeddings=[vec.tolist()]\n",
    "    )\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Section 5: Query Interface\n",
    "\n",
    "```python\n",
    "def query_rag(prompt, k=3):\n",
    "    query_embed = embedder.encode(prompt).tolist()\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embed],\n",
    "        n_results=k\n",
    "    )\n",
    "    return results[\"documents\"][0]\n",
    "\n",
    "query = \"What is the purpose of supervised learning?\"\n",
    "top_chunks = query_rag(query)\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"\\nChunk {i+1}:\\n{chunk}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Lab Wrap-Up\n",
    "\n",
    "| Feature                            | âœ… |\n",
    "|------------------------------------|----|\n",
    "| Chunks embedded and indexed        | âœ…  \n",
    "| Query returns top-k docs via vector search | âœ…  \n",
    "| ChromaDB / FAISS backend support   | âœ…  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  What You Learned\n",
    "\n",
    "- Vector DBs let you **retrieve semantically relevant data**, not keyword matches  \n",
    "- Chroma is simple, open-source, and plug-and-play for RAG setups  \n",
    "- This is the core of **document-grounded LLMs**  \n",
    "- You just built the **retriever half of RAG**\n",
    "\n",
    "---\n",
    "\n",
    "Next lab brings in **metadata awareness**:\n",
    "\n",
    "> ðŸ§  `09_lab_metadata_filtering_in_retrieval.ipynb`  \n",
    "Letâ€™s add filters like **source, date, author**, and build a **hybrid semantic + structured search engine**.\n",
    "\n",
    "You ready to query like a god, Professor?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
