{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìö Table of Contents\n",
                "\n",
                "\n",
                "- [üõ°Ô∏è Dropout Regularization](#dropout-regularization)\n",
                "  - [‚ùì What is dropout and why it helps prevent overfitting?](#what-is-dropout-and-why-it-helps-prevent-overfitting)\n",
                "  - [‚öôÔ∏è How dropout is implemented in PyTorch and TensorFlow](#how-dropout-is-implemented-in-pytorch-and-tensorflow)\n",
                "  - [üéØ Trade-offs in choosing the right dropout rate](#trade-offs-in-choosing-the-right-dropout-rate)\n",
                "- [üìä Batch Normalization](#batch-normalization)\n",
                "  - [‚ö° Role of Batch Normalization in accelerating convergence and stabilizing training](#role-of-batch-normalization-in-accelerating-convergence-and-stabilizing-training)\n",
                "  - [üìâ How it works: Normalizing activations per mini-batch](#how-it-works-normalizing-activations-per-mini-batch)\n",
                "  - [üß™ Implementing BatchNorm in both PyTorch and TensorFlow](#implementing-batchnorm-in-both-pytorch-and-tensorflow)\n",
                "- [üìè L1/L2 Regularization](#l1l2-regularization)\n",
                "  - [üîç L1 vs L2 regularization: What they are and how they work](#l1-vs-l2-regularization-what-they-are-and-how-they-work)\n",
                "  - [üß∞ How to apply L1/L2 regularization in PyTorch and TensorFlow](#how-to-apply-l1l2-regularization-in-pytorch-and-tensorflow)\n",
                "  - [üß† How regularization affects model complexity and generalization](#how-regularization-affects-model-complexity-and-generalization)\n",
                "  \n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **1. Dropout Regularization**  \n",
                "**Focus:** Stochastic neuron deactivation and framework implementations  \n",
                "```mermaid\n",
                "%%{init: {'theme': 'base', 'themeVariables': {'fontSize': '12px'}}}%%\n",
                "flowchart TD\n",
                "    subgraph Dropout[\"Dropout Mechanics\"]\n",
                "        direction TB\n",
                "\n",
                "        subgraph Concept[\"During Training (p=0.5)\"]\n",
                "            direction LR\n",
                "            N1[Neuron 1] -->|Active| Out\n",
                "            N2[Neuron 2] -->|Inactive| X\n",
                "            N3[Neuron 3] -->|Active| Out\n",
                "            style X stroke-dasharray:5,5,stroke:#cc0000\n",
                "        end\n",
                "\n",
                "        subgraph Math[\"Mathematics\"]\n",
                "            Train[[\"Training: Multiply by 1/(1-p)<br/>≈∑ = y * Bernoulli(p)\"]]\n",
                "            Infer[[\"Inference: No scaling\"]]\n",
                "            Train --> Infer\n",
                "        end\n",
                "\n",
                "        subgraph Code[\"Implementation\"]\n",
                "            direction LR\n",
                "            PT[[\"PyTorch:<br/>nn.Dropout(p=0.5)\"]]:::pytorch\n",
                "            TF[[\"TensorFlow:<br/>keras.layers.Dropout(0.5)\"]]:::tensorflow\n",
                "        end\n",
                "\n",
                "        Concept --> Math --> Code\n",
                "    end\n",
                "\n",
                "    classDef pytorch fill:#ffe6e6,stroke:#cc0000\n",
                "    classDef tensorflow fill:#e6f3ff,stroke:#0066cc\n",
                "```\n",
                "\n",
                "---\n",
                "\n",
                "### **2. Batch Normalization**  \n",
                "**Focus:** Normalization flow and framework implementations  \n",
                "```mermaid\n",
                "%%{init: {'theme': 'base', 'themeVariables': {'fontSize': '12px'}}}%%\n",
                "flowchart LR\n",
                "    subgraph BatchNorm[\"BatchNorm Process\"]\n",
                "        direction TB\n",
                "\n",
                "        Input --> Norm[[\"Normalize:<br/>(x - Œº_batch)/œÉ_batch\"]]\n",
                "        Norm --> Scale[[\"Scale & Shift:<br/>Œ≥¬∑x + Œ≤\"]]\n",
                "        Scale --> Output\n",
                "\n",
                "        subgraph Stats[\"Batch Statistics\"]\n",
                "            Œº[Mean] --> Norm\n",
                "            œÉ[Std Dev] --> Norm\n",
                "        end\n",
                "\n",
                "        subgraph Params[\"Learnable Parameters\"]\n",
                "            Œ≥[Gamma] --> Scale\n",
                "            Œ≤[Beta] --> Scale\n",
                "        end\n",
                "\n",
                "        subgraph Code[\"Implementation\"]\n",
                "            PT[[\"PyTorch:<br/>nn.BatchNorm1d()\"]]:::pytorch\n",
                "            TF[[\"TensorFlow:<br/>layers.BatchNormalization()\"]]:::tensorflow\n",
                "        end\n",
                "\n",
                "        Scale --> Code\n",
                "    end\n",
                "\n",
                "    classDef pytorch fill:#ffe6e6,stroke:#cc0000\n",
                "    classDef tensorflow fill:#e6f3ff,stroke:#0066cc\n",
                "```\n",
                "\n",
                "---\n",
                "\n",
                "### **3. L1/L2 Regularization**  \n",
                "**Focus:** Loss modification and weight penalties  \n",
                "```mermaid\n",
                "%%{init: {'theme': 'base', 'themeVariables': {'fontSize': '12px'}}}%%\n",
                "flowchart TD\n",
                "    subgraph Reg[\"Regularization Types\"]\n",
                "        direction TB\n",
                "\n",
                "        subgraph L2[\"L2 Regularization\"]\n",
                "            direction TB\n",
                "            Formula2[[\"Loss += Œª‚àëw¬≤\"]] --> Effect2[[\"Small weights\"]]\n",
                "        end\n",
                "\n",
                "        subgraph L1[\"L1 Regularization\"]\n",
                "            direction TB\n",
                "            Formula1[[\"Loss += Œª‚àë|w|\"]] --> Effect1[[\"Sparse weights\"]]\n",
                "        end\n",
                "\n",
                "        subgraph Code[\"Implementation\"]\n",
                "            direction LR\n",
                "            PT[[\"PyTorch:<br/>optim.SGD(weight_decay=Œª)\"]]:::pytorch\n",
                "            TF[[\"TensorFlow:<br/>keras.regularizers.L2(l=Œª)\"]]:::tensorflow\n",
                "        end\n",
                "\n",
                "        L1 --> Code\n",
                "        L2 --> Code\n",
                "    end\n",
                "\n",
                "    classDef pytorch fill:#ffe6e6,stroke:#cc0000\n",
                "    classDef tensorflow fill:#e6f3ff,stroke:#0066cc\n",
                "```\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "# <a id=\"dropout-regularization\"></a>üõ°Ô∏è Dropout Regularization\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"what-is-dropout-and-why-it-helps-prevent-overfitting\"></a>‚ùì What is dropout and why it helps prevent overfitting?\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"how-dropout-is-implemented-in-pytorch-and-tensorflow\"></a>‚öôÔ∏è How dropout is implemented in PyTorch and TensorFlow\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"trade-offs-in-choosing-the-right-dropout-rate\"></a>üéØ Trade-offs in choosing the right dropout rate\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"batch-normalization\"></a>üìä Batch Normalization\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"role-of-batch-normalization-in-accelerating-convergence-and-stabilizing-training\"></a>‚ö° Role of Batch Normalization in accelerating convergence and stabilizing training\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"how-it-works-normalizing-activations-per-mini-batch\"></a>üìâ How it works: Normalizing activations per mini-batch\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "# <a id=\"implementing-batchnorm-in-both-pytorch-and-tensorflow\"></a>üß™ Implementing BatchNorm in both PyTorch and TensorFlow\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"l1l2-regularization\"></a>üìè L1/L2 Regularization\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"l1-vs-l2-regularization-what-they-are-and-how-they-work\"></a>üîç L1 vs L2 regularization: What they are and how they work\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"how-to-apply-l1l2-regularization-in-pytorch-and-tensorflow\"></a>üß∞ How to apply L1/L2 regularization in PyTorch and TensorFlow\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <a id=\"how-regularization-affects-model-complexity-and-generalization\"></a>üß† How regularization affects model complexity and generalization\n"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
